---
layout: post
title: "Day 18 â€“ Juneteenth"
date: 2025-06-19
author: Michael Orishagbemi
permalink: /day18.html
tags: ["Machine Learning", "DecisionTrees", "GiniPurity", "Binning", "One-Hot Encoding"]

what_i_learned: |
  Today I finish the previous Decision Trees video I talked about where I learned more about its advanced concepts. For example, Gini Impurity is the probability that we mislabel a data point, its Gini but its also the measure we use to determine when a split should occur at each node. Binning is a preprocessing technique that's used to group data into smaller chunks to better categorize them.  These features can also be used with another technique, One-Hot encoding, to convert categorical data into numeric data or rather booleans. Additionally this newfound knoweldge help me in my implementation of calculations into my ELM and KNN models, as the strings were messing me up. I also went to the Driving Study Dr. Mack shouted out and had a fun time. I was really impressed with the technology they made.
 
blockers: |
  No blockers today.
  
reflection: |
  Today was a relaxed day, techniques such as binning and gini impurity are seemingly simple but in regards to decision trees they are vital in splitting data. For one-hot encoding, I remember using it a while ago but I feel as though the video provided today gave me a better understanding of the technique and how easy it is to implement (pd.Get_Dummies() is really all you need). The techniques helped me convert my categorical data into bools for my assignment, but the tricky parts like shaping my training and testing data to have the same shape were tough. Luckily my mentor Ms. Amara was able to clarify everything for me. Last but not least, the Driving study was really short but I enjoyed it nonetheless, that 'car' they made was really cool. It's crazy to think stuff like that is being made at Morgan, its really impressive.
---
