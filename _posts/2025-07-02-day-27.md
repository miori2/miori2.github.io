---
layout: post
title: "Day 27 â€“ Practice for our Presentation"
date: 2025-07-02
author: Michael Orishagbemi
permalink: /day27.html
tags: ['Machine Learning', 'Alzheimers Disease', 'Overleaf', 'Models']

what_i_learned: |
  Today I continued to work on my research paper. Most of my day today was trying to successfully implement all the specified model methods (ELM, KNN, SVM, Decision Trees, Random Forest) into my dataset and evaluate the metrics for each model (Mean Absolute Error, Mean Squared Error, & Root Mean Square Error and its percentage difference) and how long each model took to be trained on the data. After inputting my results in Overleaf, I then tried to balance my data. Balancing is essentially making the values of our target features 50/50. Balancing helps prevent bias in models so that they don't end up favoring one class over another and they even improve performance by allowing a model to learn from all classes, leading to more accurate predictions. 

blockers: |
  I was a little confused on why MAE and MSE were producing the same values but I realize that's just how it works.
  
reflection: |
  Today was a slow day. I implemented my models one by one and having to go back and see which variable I assinged to which was a confusing and laborious process. While I wouldn't say it was a challenge per se and its implementation wasn't even neccesary to my assignment, I wasn't able to get a good decision tree visualization for my data since I wasn't sure what to put as the feature names and I didn't want to have to put every one of them in a list. Balancing my data was a bit confusing at first but I looked up some videos to get a better idea of how to go about things. I'm still not fully finished with my model implementation (I'm busy with Random Forest) but once I'm done I'll have to look at the research papers provided to us to properly tackle the literature part of my paper.
---
